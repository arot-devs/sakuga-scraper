{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "context:\n",
    "- All images from sakugabooru has been downloaded, with schema:\n",
    "    -  `./data/post_{id}/post_{id}.{ext}`\n",
    "    - `./data/post_{id}/post_{id}.json`\n",
    "- Now we need to upload them to huggingface by tarring it.\n",
    "\n",
    "To install the libraries:\n",
    "\n",
    "```bash\n",
    "pip install unibox hfutils\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import unibox as ub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get available files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all files: 404160\n",
      "image files: 8680, video files: 155238, json files: 240242\n",
      "total unique files: 404160\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "data_dir = \"/rmt/yada/dev/sakuga-scraper/data\"\n",
    "output_dir = \"/rmt/yada/dev/sakuga-scraper/tars\"\n",
    "\n",
    "# Collect all valid media files\n",
    "all_files = ub.traverses(\"/rmt/yada/dev/sakuga-scraper/data\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert extensions to sets for validation\n",
    "image_extensions = set(ub.IMG_FILES) - {'.gif'}\n",
    "video_extensions = {'.webm', '.mp4', '.gif'}\n",
    "\n",
    "# Categorize files\n",
    "image_files = [f for f in all_files if Path(f).suffix in image_extensions]\n",
    "video_files = [f for f in all_files if Path(f).suffix in video_extensions]\n",
    "json_files = [f for f in all_files if Path(f).suffix == '.json']\n",
    "\n",
    "# Recompute lengths\n",
    "total_unique_files = len(set(image_files + video_files + json_files))\n",
    "print(f\"all files: {len(all_files)}\\nimage files: {len(image_files)}, video files: {len(video_files)}, json files: {len(json_files)}\\ntotal unique files: {total_unique_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/rmt/yada/dev/sakuga-scraper/data/post_100112/sakuga_100112.json'],\n",
       " ['/rmt/yada/dev/sakuga-scraper/data/post_122629/sakuga_122629.jpg'],\n",
       " ['/rmt/yada/dev/sakuga-scraper/data/post_102725/sakuga_102725.mp4'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_files[:1], image_files[:1], video_files[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((272, 272758), (273, 273264))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def determine_tar_info(files: List[str], modulo: int = 1000):\n",
    "    \"\"\"\n",
    "    Determine how many full tars can be created and the current last post number.\n",
    "\n",
    "    Args:\n",
    "        files (List[str]): List of file paths (images/videos).\n",
    "        modulo (int): Constant range of IDs per tar file (default: 10,000).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (number_of_full_tars, last_post_id)\n",
    "    \"\"\"\n",
    "    post_ids = []\n",
    "    for file_path in files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        try:\n",
    "            post_id = int(filename.split('_')[1].split('.')[0])\n",
    "            post_ids.append(post_id)\n",
    "        except (IndexError, ValueError):\n",
    "            print(f\"Skipping file with invalid format: {filename}\")\n",
    "            continue\n",
    "\n",
    "    if not post_ids:\n",
    "        return 0, None\n",
    "\n",
    "    last_post_id = max(post_ids)\n",
    "    number_of_full_tars = (last_post_id + 1) // modulo\n",
    "\n",
    "    return number_of_full_tars, last_post_id\n",
    "\n",
    "\n",
    "# full tar count, last post id\n",
    "determine_tar_info(image_files), determine_tar_info(video_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do the tarring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can make 273 full tars, last post id is 273264\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "def generate_tar_from_files(\n",
    "    files: List[str], \n",
    "    output_dir: str, \n",
    "    id: int, \n",
    "    modulo: int = 1000\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Create tar files containing files (images/videos) grouped by post ID ranges.\n",
    "\n",
    "    Args:\n",
    "        files (List[str]): List of file paths (images/videos).\n",
    "        output_dir (str): Directory to store the tar files.\n",
    "        id (int): The ID used to determine the range of files to include in the tar.\n",
    "        modulo (int): Constant range of IDs per tar file (default: 10,000).\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of created tar file paths.\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Determine ID range\n",
    "    range_start = id * modulo\n",
    "    range_end = (id + 1) * modulo\n",
    "\n",
    "    # Filter files by ID range\n",
    "    files_in_range = []\n",
    "    for file_path in files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        try:\n",
    "            post_id = int(filename.split('_')[1].split('.')[0])\n",
    "        except (IndexError, ValueError):\n",
    "            print(f\"Skipping file with invalid format: {filename}\")\n",
    "            continue\n",
    "\n",
    "        if range_start <= post_id < range_end:\n",
    "            # add the file itself\n",
    "            files_in_range.append(file_path)\n",
    "\n",
    "            # add metadata json\n",
    "            metadata_file = Path(file_path).with_suffix('.json')\n",
    "            if metadata_file.exists():\n",
    "                files_in_range.append(str(metadata_file))\n",
    "\n",
    "\n",
    "    if not files_in_range:\n",
    "        print(f\"No files found in range {range_start}-{range_end}.\")\n",
    "        return []\n",
    "\n",
    "    tar_file_path = output_dir / f\"{id}.tar\"\n",
    "\n",
    "    # Create the tar\n",
    "    with tarfile.open(tar_file_path, \"w\") as tar:\n",
    "        for file_path in files_in_range:\n",
    "            tar.add(file_path, arcname=os.path.basename(file_path))\n",
    "\n",
    "    print(f\"Created tar: {tar_file_path} with {len(files_in_range)} files.\")\n",
    "\n",
    "    return [str(tar_file_path)]\n",
    "\n",
    "# Example usage:\n",
    "# Suppose we have a collection of images & videos:\n",
    "# files = [\n",
    "#     \"/path/to/sankaku_16465.jpg\",\n",
    "#     \"/path/to/sankaku_20000.mp4\",\n",
    "#     ...\n",
    "# ]\n",
    "\n",
    "# See how many tars and the highest post ID:\n",
    "media_files = video_files + image_files\n",
    "tar_count, last_id = determine_tar_info(media_files)\n",
    "print(\"We can make\", tar_count, \"full tars, last post id is\", last_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created tar: /lv0/tars/0.tar with 600 files.\n",
      "['/lv0/tars/0.tar']\n"
     ]
    }
   ],
   "source": [
    "# Create the tar for the first batch (id=0):\n",
    "!mkdir -p /lv0/tar\n",
    "tars_created = generate_tar_from_files(media_files, output_dir=\"/lv0/tars\", id=0)\n",
    "print(tars_created)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b13271fcb047cba0de98bfa4202add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing tar file '/lv0/tars/0.tar' ...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/lv0/tars/0.json'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hfutils.index.make import tar_create_index\n",
    "\n",
    "# Create index for the generated tars\n",
    "# tar_create_index(src_tar_file=\"/rmt/yada/dev/sakuga-scraper/tars/0.tar\")\n",
    "tar_create_index(src_tar_file=\"/lv0/tars/0.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing partial tar read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files verified successfully via local partial-read checks.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "\n",
    "def test_local_partial_read(tar_path: str, index_json_path: str):\n",
    "    \"\"\"\n",
    "    Perform local partial reads of an uncompressed tar file to verify offsets and sizes\n",
    "    match the metadata in the JSON index.\n",
    "\n",
    "    :param tar_path: Path to the tar file.\n",
    "    :param index_json_path: Path to the JSON index (the .tar.json file).\n",
    "    \"\"\"\n",
    "    with open(index_json_path, 'r', encoding='utf-8') as jf:\n",
    "        index_data = json.load(jf)\n",
    "\n",
    "    # Sanity check: Compare tar size\n",
    "    reported_size = index_data.get(\"filesize\", None)\n",
    "    actual_size = os.path.getsize(tar_path)\n",
    "    if reported_size and reported_size != actual_size:\n",
    "        raise ValueError(f\"Tar size mismatch! JSON says {reported_size} bytes, actual is {actual_size} bytes.\")\n",
    "\n",
    "    with open(tar_path, \"rb\") as tar_f:\n",
    "        for fname, info in index_data[\"files\"].items():\n",
    "            offset = info[\"offset\"]\n",
    "            size = info[\"size\"]\n",
    "            expected_sha256 = info[\"sha256\"]\n",
    "\n",
    "            # Seek to offset and read exactly `size` bytes\n",
    "            tar_f.seek(offset, 0)\n",
    "            data = tar_f.read(size)\n",
    "            if len(data) != size:\n",
    "                raise ValueError(f\"Read {len(data)} bytes instead of {size} for '{fname}'.\")\n",
    "\n",
    "            # Compute SHA-256 and compare\n",
    "            actual_sha256 = hashlib.sha256(data).hexdigest()\n",
    "            if actual_sha256 != expected_sha256:\n",
    "                raise ValueError(f\"SHA mismatch for '{fname}'. Expected {expected_sha256}, got {actual_sha256}.\")\n",
    "\n",
    "    print(\"All files verified successfully via local partial-read checks.\")\n",
    "\n",
    "\n",
    "test_local_partial_read(\"/lv0/tars/0.tar\", \"/lv0/tars/0.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created tar: /lv0/tars/273.tar with 496 files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/lv0/tars/273.tar']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_tar_from_files(media_files, output_dir=\"/lv0/tars\", id=273)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tarring the entire set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0557e54d0bce48f3aba219ebf8b470c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created tar: ../tars/1.tar with 3011 files.\n",
      "['../tars/1.tar']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54217658da474bd8b03606cf6a56f1de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing tar file '../tars/1.tar' ...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files verified successfully via local partial-read checks.\n",
      "Created tar: ../tars/2.tar with 4460 files.\n",
      "['../tars/2.tar']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81ec72a9eb04d6881ffa06370c41778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing tar file '../tars/2.tar' ...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files verified successfully via local partial-read checks.\n",
      "Created tar: ../tars/3.tar with 4263 files.\n",
      "['../tars/3.tar']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ea264f17b641b7b108e85dee875074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing tar file '../tars/3.tar' ...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files verified successfully via local partial-read checks.\n",
      "Created tar: ../tars/4.tar with 4335 files.\n",
      "['../tars/4.tar']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c92f2817024ac6abb32785347b7d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing tar file '../tars/4.tar' ...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files verified successfully via local partial-read checks.\n",
      "Created tar: ../tars/5.tar with 3947 files.\n",
      "['../tars/5.tar']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2866e705abe6460da666335fe3f11d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing tar file '../tars/5.tar' ...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files verified successfully via local partial-read checks.\n",
      "Created tar: ../tars/6.tar with 4389 files.\n",
      "['../tars/6.tar']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd572cf52274671bd882f37849aaa37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing tar file '../tars/6.tar' ...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files verified successfully via local partial-read checks.\n",
      "Created tar: ../tars/7.tar with 4406 files.\n",
      "['../tars/7.tar']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fb8da192984efca7f7af629d339b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing tar file '../tars/7.tar' ...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files verified successfully via local partial-read checks.\n",
      "Created tar: ../tars/8.tar with 4340 files.\n",
      "['../tars/8.tar']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5902be831843c4ba5ef4cfb90463c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing tar file '../tars/8.tar' ...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files verified successfully via local partial-read checks.\n",
      "Created tar: ../tars/9.tar with 2 files.\n",
      "['../tars/9.tar']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dcb080de6eb45a2b915370bbd8b754a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing tar file '../tars/9.tar' ...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files verified successfully via local partial-read checks.\n",
      "Created tar: ../tars/10.tar with 4705 files.\n",
      "['../tars/10.tar']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cfab870607c4958b371f33a4e18c013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing tar file '../tars/10.tar' ...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files verified successfully via local partial-read checks.\n",
      "Created tar: ../tars/11.tar with 6668 files.\n",
      "['../tars/11.tar']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce71c352035b432fad625ef93e7e5749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing tar file '../tars/11.tar' ...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files verified successfully via local partial-read checks.\n",
      "Created tar: ../tars/12.tar with 6963 files.\n",
      "['../tars/12.tar']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f5cc5416c7449eb9c774be7624b9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing tar file '../tars/12.tar' ...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files verified successfully via local partial-read checks.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# since we already created the first tar, we can start from 1\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, tar_count)):\n\u001b[0;32m----> 5\u001b[0m     tars_created \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_tar_from_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmedia_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../tars\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tars_created)\n\u001b[1;32m      7\u001b[0m     tar_create_index(src_tar_file\u001b[38;5;241m=\u001b[39mtars_created[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[12], line 53\u001b[0m, in \u001b[0;36mgenerate_tar_from_files\u001b[0;34m(files, output_dir, id, modulo)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mopen(tar_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tar:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m files_in_range:\n\u001b[0;32m---> 53\u001b[0m         \u001b[43mtar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marcname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated tar: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtar_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(files_in_range)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mstr\u001b[39m(tar_file_path)]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/tarfile.py:2180\u001b[0m, in \u001b[0;36mTarFile.add\u001b[0;34m(self, name, arcname, recursive, filter)\u001b[0m\n\u001b[1;32m   2178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tarinfo\u001b[38;5;241m.\u001b[39misreg():\n\u001b[1;32m   2179\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m bltn_open(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m-> 2180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2182\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tarinfo\u001b[38;5;241m.\u001b[39misdir():\n\u001b[1;32m   2183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddfile(tarinfo)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/tarfile.py:2208\u001b[0m, in \u001b[0;36mTarFile.addfile\u001b[0;34m(self, tarinfo, fileobj)\u001b[0m\n\u001b[1;32m   2206\u001b[0m \u001b[38;5;66;03m# If there's data to follow, append it.\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2208\u001b[0m     \u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2209\u001b[0m     blocks, remainder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdivmod\u001b[39m(tarinfo\u001b[38;5;241m.\u001b[39msize, BLOCKSIZE)\n\u001b[1;32m   2210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remainder \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/tarfile.py:252\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[0;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[1;32m    250\u001b[0m blocks, remainder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdivmod\u001b[39m(length, bufsize)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(blocks):\n\u001b[0;32m--> 252\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buf) \u001b[38;5;241m<\u001b[39m bufsize:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected end of data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# since we already created the first tar, we can start from 1\n",
    "for i in tqdm(range(1, tar_count)):\n",
    "    tars_created = generate_tar_from_files(media_files, output_dir=\"/lv0/tars\", id=i)\n",
    "    print(tars_created)\n",
    "    tar_create_index(src_tar_file=tars_created[0])\n",
    "\n",
    "    test_local_partial_read(tars_created[0], f\"/lv0/tars/{i}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read and put together all jsons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94742a7624c1424c9aea170f952e1c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading batches:   0%|          | 0/240242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_jsons = ub.concurrent_loads(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
